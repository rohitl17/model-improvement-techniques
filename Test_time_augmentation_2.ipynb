{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications.densenet import DenseNet121\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,CSVLogger,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score,classification_report,auc,roc_curve\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def img_standardization(x):\n",
    "    \n",
    "#     x=cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x=x.astype('float16')/255.\n",
    "#     return x\n",
    "    return ((x-imagenet_mean)/imagenet_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        ),\n",
    "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.9, 1.1)),\n",
    "        iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, batch_size = 32):\n",
    "    indices = np.arange(len(X))\n",
    "    print (indices)\n",
    "    batch=[]\n",
    "    while True:\n",
    "            for i in indices:\n",
    "                batch.append(i)\n",
    "                if len(batch)==batch_size or i==indices[-1]:\n",
    "                    x=augmentation(images=X[batch])\n",
    "                    x=img_standardization(x)\n",
    "                    yield x\n",
    "                    batch=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation1 = iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        )\n",
    "\n",
    "augmentation2=iaa.PiecewiseAffine(scale=(0.001, 0.025))\n",
    "\n",
    "augmentation3=iaa.Multiply((0.9, 1.1))\n",
    "augmentation4=iaa.ContrastNormalization((0.9, 1.1))\n",
    "\n",
    "augmentation5=iaa.GaussianBlur(sigma=(0.0, 0.1))\n",
    "augmentation6=iaa.Sharpen(alpha=(0.0, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs_for_all_augs(X, batch_size = 32):\n",
    "    final_preds1=[]\n",
    "    final_preds2=[]\n",
    "    final_preds3=[]\n",
    "    final_preds4=[]\n",
    "    final_preds5=[]\n",
    "    final_preds6=[]\n",
    "    final_preds7=[]\n",
    "    \n",
    "    for idx, i in enumerate(X):\n",
    "        x=augmentation1(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds1=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds1.append(preds1[0][1])\n",
    "        \n",
    "        x=augmentation2(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds2=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds2.append(preds2[0][1])\n",
    "        \n",
    "        x=augmentation3(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds3=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds3.append(preds3[0][1])\n",
    "        \n",
    "        x=augmentation4(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds4=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds4.append(preds4[0][1])\n",
    "        \n",
    "        x=augmentation5(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds5=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds5.append(preds5[0][1])\n",
    "        \n",
    "        x=augmentation6(images=i)\n",
    "        x=img_standardization(x)\n",
    "        preds6=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds6.append(preds6[0][1])\n",
    "        \n",
    "        x=img_standardization(i)\n",
    "        preds7=new_model.predict(np.expand_dims(x, axis=0))\n",
    "        final_preds7.append(preds7[0][1])\n",
    "\n",
    "        print (idx)\n",
    "    return (final_preds1, final_preds2, final_preds3, final_preds4, final_preds5, final_preds6, final_preds7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam=Adam(lr=1e-4)\n",
    "\n",
    "#Model declaration:Densenet \n",
    "dense_model = DenseNet121(weights='imagenet', include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "preds = Dense(14,activation='sigmoid')(dense_model.output)\n",
    "model = Model(dense_model.input,preds)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.load_weights('/opt/bucketdata/Users/Rohit/15_pathology_model/NIH_more_than_decent_weights/updated_best_weights.h5')\n",
    "\n",
    "\n",
    "#Model parameters for compiling\n",
    "\n",
    "model.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = Dense(2,activation='softmax')(model.get_layer('avg_pool').output)\n",
    "new_model = Model(model.input,new_preds)\n",
    "new_model.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.load_weights('./Weights/CHAI_PvsNP_newlabels_transferlearned_fromNIHPvsNP.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=[]\n",
    "for i in y_test:\n",
    "    if i==2:\n",
    "        Y_test.append(1)\n",
    "    else:\n",
    "        Y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max vote TTA/Average TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_probs1, final_probs2, final_probs3, final_probs4, final_probs5, final_probs6, final_probs7 = get_probs_for_all_augs(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Predictions_from_valsaved_woaug_Nov\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs_affine.npy', np.array(final_probs1))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs2_piecewiseaffine.npy', np.array(final_probs2))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs3_multiply.npy', np.array(final_probs3))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs4_contrast.npy', np.array(final_probs4))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs5_gaussian.npy', np.array(final_probs5))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs6_sharpen.npy', np.array(final_probs6))\n",
    "np.save('./Predictions_from_valsaved_woaug_Nov/probs7_original.npy', np.array(final_probs7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs_affine.npy\",mmap_mode='r')\n",
    "y2=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs2_piecewiseaffine.npy\", mmap_mode='r')\n",
    "\n",
    "y3=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs3_multiply.npy\",mmap_mode='r')\n",
    "y4=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs4_contrast.npy\", mmap_mode='r')\n",
    "\n",
    "y5=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs5_gaussian.npy\",mmap_mode='r')\n",
    "y6=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs6_sharpen.npy\",mmap_mode='r')\n",
    "y7=np.load(\"./Predictions_from_valsaved_woaug_Nov/probs7_original.npy\",mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds=(y3+y4+y5+y6+y7)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.zeros((len(y1),7))\n",
    "threshold=0.0305\n",
    "for idx, i in enumerate(y1):\n",
    "#     if y1[idx]>=threshold:\n",
    "#         final[idx][0]=1\n",
    "#     if y2[idx]>=threshold:\n",
    "#         final[idx][1]=1\n",
    "    if y3[idx]>=threshold:\n",
    "        final[idx][2]=1\n",
    "    if y4[idx]>=threshold:\n",
    "        final[idx][3]=1\n",
    "    if y5[idx]>=threshold:\n",
    "        final[idx][4]=1\n",
    "    if y6[idx]>=threshold:\n",
    "        final[idx][5]=1\n",
    "    if y7[idx]>=threshold:\n",
    "        final[idx][6]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vote=np.sum(final, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds=[]\n",
    "for i in final_vote:\n",
    "    if i>=3:\n",
    "        class_preds.append(1)\n",
    "    else:\n",
    "        class_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=class_preds\n",
    "# Y_test=np.argmax(Y_test,axis=-1)\n",
    "target_names = ['normal','Pathology']\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print (confusion_matrix(Y_test,Y_pred))\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred,target_names=target_names))\n",
    "\n",
    "print(\"Kappa score:\")\n",
    "print(cohen_kappa_score(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
